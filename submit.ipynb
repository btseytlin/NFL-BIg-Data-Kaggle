{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from kaggle.competitions import nflrush\n",
    "import tqdm\n",
    "import re\n",
    "from string import punctuation\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [15,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "def crps(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred), axis=1)\n",
    "\n",
    "def yard_to_cdf(yard):\n",
    "    yard = np.round(yard).astype(int)\n",
    "    indices = yard+99\n",
    "    cdfs = np.zeros((yard.shape[0], 199))\n",
    "    for i in range(len(cdfs)):\n",
    "        cdfs[i, indices[i]:] = 1\n",
    "    return cdfs\n",
    "\n",
    "def cdf_to_yard(cdf):\n",
    "    yard_index = (cdf==1).argmax(axis=1)\n",
    "    yard = yard_index-99\n",
    "    return yard\n",
    "\n",
    "def clean_StadiumType(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    txt = txt.lower()\n",
    "    txt = ''.join([c for c in txt if c not in punctuation])\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    txt = txt.replace('outside', 'outdoor')\n",
    "    txt = txt.replace('outdor', 'outdoor')\n",
    "    txt = txt.replace('outddors', 'outdoor')\n",
    "    txt = txt.replace('outdoors', 'outdoor')\n",
    "    txt = txt.replace('oudoor', 'outdoor')\n",
    "    txt = txt.replace('indoors', 'indoor')\n",
    "    txt = txt.replace('ourdoor', 'outdoor')\n",
    "    txt = txt.replace('retractable', 'rtr.')\n",
    "    return txt\n",
    "\n",
    "def transform_StadiumType(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    if 'outdoor' in txt or 'open' in txt:\n",
    "        return 1\n",
    "    if 'indoor' in txt or 'closed' in txt:\n",
    "        return 0\n",
    "    return np.nan\n",
    "\n",
    "def str_to_seconds(txt):\n",
    "    txt = txt.split(':')\n",
    "    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n",
    "    return ans\n",
    "\n",
    "def str_to_float(txt):\n",
    "    try:\n",
    "        return float(txt)\n",
    "    except Exception as e:\n",
    "        return np.NaN\n",
    "\n",
    "def map_weather(txt):\n",
    "    ans = 1\n",
    "    if pd.isna(txt):\n",
    "        return 0\n",
    "    if 'partly' in txt:\n",
    "        ans*=0.5\n",
    "    if 'climate controlled' in txt or 'indoor' in txt:\n",
    "        return ans*3\n",
    "    if 'sunny' in txt or 'sun' in txt:\n",
    "        return ans*2\n",
    "    if 'clear' in txt:\n",
    "        return ans\n",
    "    if 'cloudy' in txt:\n",
    "        return -ans\n",
    "    if 'rain' in txt or 'rainy' in txt:\n",
    "        return -2*ans\n",
    "    if 'snow' in txt:\n",
    "        return -3*ans\n",
    "    return 0\n",
    "\n",
    "def new_orientation(angle, play_direction):\n",
    "    if play_direction == 0:\n",
    "        new_angle = 360.0 - angle\n",
    "        if new_angle == 360.0:\n",
    "            new_angle = 0.0\n",
    "        return new_angle\n",
    "    else:\n",
    "        return angle\n",
    "\n",
    "def preprocess_features(df):\n",
    "    \"\"\"Accepts df like train data, returns X, y\"\"\"\n",
    "\n",
    "    # Feature engineering\n",
    "    df['DefendersInTheBox_vs_Distance'] = (df['DefendersInTheBox'] / df['Distance'])\n",
    "    df['StadiumType'] = df['StadiumType'].apply(clean_StadiumType)\n",
    "    df['StadiumTypeShort'] = df['StadiumType'].apply(transform_StadiumType)\n",
    "    df = df.drop(['StadiumType'], axis=1)\n",
    "\n",
    "    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', \n",
    "        'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', \n",
    "        'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', \n",
    "        'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', \n",
    "        'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n",
    "\n",
    "    turf_type = df['Turf'].map(Turf)\n",
    "    df['TurfIsNatural'] = (turf_type == 'Natural')\n",
    "    df = df.drop(['Turf'], axis=1)\n",
    "\n",
    "    map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n",
    "    for abb in df['PossessionTeam'].unique():\n",
    "        map_abbr[abb] = abb\n",
    "    df['PossessionTeam'] = df['PossessionTeam'].map(map_abbr)\n",
    "    df['HomeTeamAbbr'] = df['HomeTeamAbbr'].map(map_abbr)\n",
    "    df['VisitorTeamAbbr'] = df['VisitorTeamAbbr'].map(map_abbr)\n",
    "\n",
    "    df['HomePossesion'] = (df['PossessionTeam'] == df['HomeTeamAbbr'])\n",
    "\n",
    "    df['Field_eq_Possession'] = df['FieldPosition'] == df['PossessionTeam']\n",
    "    df['HomeField'] = df['FieldPosition'] == df['HomeTeamAbbr']\n",
    "\n",
    "    # in posession\n",
    "    df['InPosession']=(((df.Team == 'home') & (df.PossessionTeam == df.HomeTeamAbbr)) | ((df.Team == 'away') & (df.PossessionTeam == df.VisitorTeamAbbr)))\n",
    "\n",
    "    df = pd.concat([df.drop(['OffenseFormation'], axis=1), pd.get_dummies(df['OffenseFormation'], prefix='Formation')], axis=1)\n",
    "    \n",
    "    df['GameClock'] = df['GameClock'].apply(str_to_seconds)\n",
    "\n",
    "    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "    df['PlayerBMI'] = 703*(df['PlayerWeight']/(df['PlayerHeight'])**2)\n",
    "\n",
    "    df['TimeHandoff'] = pd.to_datetime(df['TimeHandoff'], utc=True)\n",
    "    df['TimeSnap'] = pd.to_datetime(df['TimeSnap'], utc=True)\n",
    "    df['TimeDelta'] = (df['TimeHandoff']-df['TimeSnap']).apply(lambda x: x.total_seconds())\n",
    "    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "    df['PlayerBirthDate'] = pd.to_datetime(df['PlayerBirthDate'], utc=True)\n",
    "\n",
    "    seconds_in_year = 60*60*24*365.25\n",
    "    df['PlayerAge'] = (df['TimeHandoff']-df['PlayerBirthDate']).apply(lambda x: x.total_seconds())/seconds_in_year\n",
    "    df = df.drop(['TimeHandoff', 'TimeSnap', 'PlayerBirthDate'], axis=1)\n",
    "\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(str_to_float)\n",
    "\n",
    "    df = df.drop(['WindDirection'], axis=1)\n",
    "    df['PlayDirection'] = df['PlayDirection'].apply(lambda x: x.strip() == 'right')\n",
    "    df['IsHomeTeam'] = df['Team'].apply(lambda x: x.strip()=='home')\n",
    "\n",
    "\n",
    "\n",
    "    df['GameWeather'] = df['GameWeather'].str.lower()\n",
    "    indoor = \"indoor\"\n",
    "    df['GameWeather'] = df['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "    df['GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    df['GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    df['GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    df['GameWeather'] = df['GameWeather'].apply(map_weather)\n",
    "\n",
    "    df['IsRusher'] = df['NflId'] == df['NflIdRusher']\n",
    "    df.drop(['NflId', 'NflIdRusher'], axis=1, inplace=True)\n",
    "\n",
    "    df['X'] = df.apply(lambda row: row['X'] if row['PlayDirection'] else 120-row['X'], axis=1)\n",
    "    df['Orientation'] = df.apply(lambda row: new_orientation(row['Orientation'], row['PlayDirection']), axis=1)\n",
    "    df['Dir'] = df.apply(lambda row: new_orientation(row['Dir'], row['PlayDirection']), axis=1)\n",
    "    \n",
    "    df['YardsLeft'] = df.apply(lambda row: 100-row['YardLine'] if row['HomeField'] else row['YardLine'], axis=1)\n",
    "    df['YardsLeft'] = df.apply(lambda row: row['YardsLeft'] if row['PlayDirection'] else 100-row['YardsLeft'], axis=1)\n",
    "    \n",
    "\n",
    "    # DefensePersonnel\n",
    "    counts = []\n",
    "    for i, val in df['DefensePersonnel'].str.split(',').iteritems():\n",
    "        row = {'DL':0,\n",
    "          'LB': 0,\n",
    "          'DB': 0,\n",
    "          'OL': 0}\n",
    "        if val is np.NaN:\n",
    "            counts.append({})\n",
    "            continue\n",
    "        for item in val:\n",
    "            name, number = item.strip().split(' ')[::-1]\n",
    "            row[name] = int(number)\n",
    "        counts.append(row)\n",
    "    defense_presonell_df = pd.DataFrame(counts)\n",
    "    defense_presonell_df.columns = ['defense_'+x for x in defense_presonell_df.columns]\n",
    "    defense_presonell_df = defense_presonell_df.fillna(0).astype(int)\n",
    "    defense_presonell_df.index = df.index\n",
    "    df = pd.concat([df.drop(['DefensePersonnel'], axis=1), defense_presonell_df], axis=1)\n",
    "\n",
    "\n",
    "    # OffensePersonnel\n",
    "    counts = []\n",
    "    for i, val in df['OffensePersonnel'].str.split(',').iteritems():\n",
    "        row = {'OL': 0, 'RB': 0, 'TE': 0, 'WR': 0, 'DL': 0}\n",
    "        if val is np.NaN:\n",
    "            counts.append({})\n",
    "            continue\n",
    "        for item in val:\n",
    "            name, number = item.strip().split(' ')[::-1]\n",
    "            row[name] = int(number)\n",
    "        counts.append(row)\n",
    "    offense_personnel_df = pd.DataFrame(counts)\n",
    "    offense_personnel_df.columns = ['offense_'+x for x in offense_personnel_df.columns]\n",
    "    offense_personnel_df = offense_personnel_df.fillna(0).astype(int)\n",
    "    offense_personnel_df.index = df.index\n",
    "    df = pd.concat([df.drop(['OffensePersonnel'], axis=1), offense_personnel_df], axis=1)\n",
    "    df = sort_df(df)\n",
    "    return df\n",
    "\n",
    "def sort_df(df):\n",
    "    df = df.sort_values(by=['PlayId', 'InPosession', 'IsRusher']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def make_x(df):\n",
    "    source_play_id = df['PlayId']\n",
    "\n",
    "    cols_delete = ['GameId', 'PlayId', 'IsRusher', 'Team']\n",
    "    df = df.drop(cols_delete, axis=1)\n",
    "\n",
    "    # Fill nan\n",
    "    # df = df.fillna(-999)#, method='pad')\n",
    "\n",
    "    # Text features\n",
    "    text_cols = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype =='object':\n",
    "            text_cols.append(col)\n",
    "\n",
    "    df = df.drop(text_cols, axis=1)\n",
    "\n",
    "    # Player features\n",
    "    cols_player = ['X',\n",
    "         'Y',\n",
    "         'S',\n",
    "         'A',\n",
    "         'Dis',\n",
    "         'Orientation',\n",
    "         'Dir',\n",
    "         'JerseyNumber',\n",
    "         'PlayerHeight',\n",
    "         'PlayerWeight',\n",
    "         'PlayerBMI',\n",
    "         'PlayerAge']\n",
    "\n",
    "    all_cols_player = np.array([[f'pl{num}_'+x for x in cols_player] for num in range(1, 23)]).flatten()\n",
    "\n",
    "    X = np.array(df[cols_player]).reshape(-1, len(cols_player)*22)\n",
    "\n",
    "    play_id_index = source_play_id[::22]\n",
    "    X_df = pd.DataFrame(X, columns=all_cols_player, index=play_id_index)\n",
    "\n",
    "    assert df[cols_player].shape[0] == X_df.shape[0] * 22\n",
    "    assert df[cols_player].shape[1] == X_df.shape[1] / 22\n",
    "\n",
    "    # Play features\n",
    "    cols_play = list(df.drop(cols_player+(['Yards'] if 'Yards' in df.columns else []), axis=1).columns)\n",
    "    X_play_col = np.zeros(shape=(X.shape[0], len(cols_play)))\n",
    "    for i, col in enumerate(cols_play):\n",
    "        X_play_col[:, i] = df[col][::22]\n",
    "\n",
    "    X_play_col_df = pd.DataFrame(X_play_col, columns=cols_play, index=play_id_index)\n",
    "    assert X_df.shape[0] == X_play_col_df.shape[0]\n",
    "    X_df = pd.concat([X_df, X_play_col_df], axis=1)\n",
    "\n",
    "    assert X_df.shape[0] == source_play_id.drop_duplicates().count()\n",
    "    return X_df\n",
    "\n",
    "def make_y(X, df):\n",
    "    y = np.zeros(shape=(X.shape[0], 199))\n",
    "    for i, yard in enumerate(df['Yards'][::22]):\n",
    "        y[i, yard+99:] = np.ones(shape=(1, 100-yard))\n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n",
    "df_train = pd.read_csv('data/train.csv', dtype={'WindSpeed': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed = preprocess_features(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = make_x(df_train_preprocessed)\n",
    "y_train = make_y(X_train, df_train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23171, 309), (23171, 199))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  3  5 ...  4  2 11]\n"
     ]
    }
   ],
   "source": [
    "# Turn yard cdf to yard number, \\in (-99, 99)\n",
    "y_train_yard_num = cdf_to_yard(y_train)\n",
    "assert y_train_yard_num[0] == 8\n",
    "print(y_train_yard_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train_num, y_val_num = train_test_split(X_train, y_train_yard_num,\n",
    "                                        test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, y_train_num,\n",
    "                       categorical_feature='auto')\n",
    "val_data = lgb.Dataset(X_val, y_val_num,\n",
    "                       categorical_feature='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_cprs_eval(preds, train_data):\n",
    "    yards_true = train_data.label\n",
    "    eval_name, is_higher_better = 'mean crps', False\n",
    "    pred_cdfs = yard_to_cdf(preds)\n",
    "    true_cdfs = yard_to_cdf(yards_true)\n",
    "    errors = crps(true_cdfs, pred_cdfs)\n",
    "    eval_result = np.mean(errors)\n",
    "    return eval_name, eval_result, is_higher_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:104: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 3.59063\tvalid_0's mean crps: 0.0180514\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\tvalid_0's l1: 3.58846\tvalid_0's mean crps: 0.0180514\n",
      "[3]\tvalid_0's l1: 3.58608\tvalid_0's mean crps: 0.0180514\n",
      "[4]\tvalid_0's l1: 3.58368\tvalid_0's mean crps: 0.0180514\n",
      "[5]\tvalid_0's l1: 3.58137\tvalid_0's mean crps: 0.0180514\n",
      "[6]\tvalid_0's l1: 3.5793\tvalid_0's mean crps: 0.0180514\n",
      "[7]\tvalid_0's l1: 3.57689\tvalid_0's mean crps: 0.0180514\n",
      "[8]\tvalid_0's l1: 3.57501\tvalid_0's mean crps: 0.0180514\n",
      "[9]\tvalid_0's l1: 3.57293\tvalid_0's mean crps: 0.0180514\n",
      "[10]\tvalid_0's l1: 3.57085\tvalid_0's mean crps: 0.0180514\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l1: 3.57085\tvalid_0's mean crps: 0.0180514\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': {'mae'},\n",
    "    'metric_freq': 5,\n",
    "    'early_stopping_round': 200,\n",
    "    'max_bin': 255,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.01,\n",
    "#     'num_leaves': 31,\n",
    "    'tree_learner': 'serial',\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.01\n",
    "}\n",
    "num_iterations = 10\n",
    "bst = lgb.train(lgb_params, train_data, num_iterations, valid_sets=[val_data], feval=lgb_cprs_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_predictions(df_test, y_test, model):\n",
    "    df_test_preprocessed = preprocess_features(df_test)\n",
    "    X_test = make_x(df_test_preprocessed)    \n",
    "    yard_pred = model.predict(X_test)\n",
    "    y_pred = yard_to_cdf(yard_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3438it [13:17,  4.84it/s]\n"
     ]
    }
   ],
   "source": [
    "for df_test, y_cdf_test in tqdm.tqdm(iter_test):\n",
    "    y_pred = get_predictions(df_test, y_cdf_test, bst)\n",
    "    env.predict(pd.DataFrame(data=y_pred,columns=y_cdf_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/working/submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-65b12c09f563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_submission_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/study/NFL BIG DATA/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/competition.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcompetition.make_env.Competition.write_submission_file\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3008\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 3010\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3012\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/submission.csv'"
     ]
    }
   ],
   "source": [
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
